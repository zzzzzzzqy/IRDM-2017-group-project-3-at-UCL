{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings(\"ignore\");\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from scipy.sparse import hstack, coo_matrix, csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "\n",
    "with open('XX_train.pkl', 'rb') as infile:\n",
    "    X_train = pickle.load(infile)\n",
    "\n",
    "with open('y_train.pkl', 'rb') as infile:\n",
    "    y_train = pickle.load(infile)\n",
    "    \n",
    "with open('XX_test.pkl', 'rb') as infile:\n",
    "    X_test = pickle.load(infile)\n",
    "    \n",
    "# with open('y_test.pkl', 'rb') as infile:\n",
    "#     y_test = pickle.load(infile)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74067, 650)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We'll split our training data, 80% will go to \"train\" and 20% will go to \"test\":\n",
    "\n",
    "# Split 80-20 train vs test data\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=0)\n",
    "\n",
    "#train_x = normalize(train_x)\n",
    "#test_x = normalize(test_x)\n",
    "# train_y = train_y.values\n",
    "# test_y = test_y.values\n",
    "#train_y = train_y.astype('float64')\n",
    "#test_y = test_y.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Caculate the root mean square rooot\n",
    "def rmse(predictions, targets):\n",
    "\n",
    "    differences = predictions - targets                       #the DIFFERENCEs.\n",
    "\n",
    "    differences_squared = differences ** 2                    #the SQUAREs of ^\n",
    "\n",
    "    mean_of_differences_squared = differences_squared.mean()  #the MEAN of ^\n",
    "\n",
    "    rmse_val = np.sqrt(mean_of_differences_squared)           #ROOT of ^\n",
    "\n",
    "    return rmse_val     #get the ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# def nDCGScoresBased(pred, true, k):\n",
    "# # pred: predicted rank *score* of the authors\n",
    "# # - must be non-negative\n",
    "# # - 0 means non-CEP\n",
    "# # - the larger rank score, the better\n",
    "# # true: ground truth log-score of the author\n",
    "# # - pred and true should be aligned\n",
    "# # k: number of ground truth CEPs\n",
    "#     assert len(pred) == len(true)\n",
    "#     assert len(true) >= k\n",
    "\n",
    "#     # NOTE(hfang): ignore negative scores\n",
    "#     true = np.array(true)\n",
    "#     true[true < 0] = 0\n",
    "#     assert sum(true > 0) >= k\n",
    "\n",
    "#     # compute ideal DCG\n",
    "#     true_sorted = sorted(true, reverse=True)\n",
    "#     IDCGk = 0\n",
    "#     for r, x in enumerate(true_sorted[:k]):\n",
    "#         IDCGk += x / np.log2(r + 2)\n",
    "\n",
    "#     # compute actual DCG\n",
    "#     pred = np.array(pred)\n",
    "#     m = min(sum(pred != 0), k)\n",
    "#     assert sum(pred < 0) == 0\n",
    "#     temp = pred.argsort()[::-1]\n",
    "#     rank_pred = np.empty(len(pred), int)\n",
    "#     rank_pred[temp] = np.arange(len(pred))\n",
    "#     assert (pred[rank_pred < m] > 0).all()\n",
    "#     predscore_with_rank = sorted(zip(rank_pred, true), \\\n",
    "#             key=lambda x:x[0])\n",
    "#     DCGk = 0\n",
    "#     for r, x in predscore_with_rank[:m]:\n",
    "#         DCGk += x / np.log2(r + 2)\n",
    "        \n",
    "#     score = DCGk/IDCGk\n",
    "#     return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor,ExtraTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "import re\n",
    "import os\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- time use: 1.81 minutes ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "start_time = time.time()\n",
    "\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(140, 70), \n",
    "                        activation='logistic', \n",
    "                        solver='lbfgs', \n",
    "                        alpha=0.5, #l2 penalty \n",
    "                        batch_size='auto', \n",
    "                        learning_rate='constant', \n",
    "                        learning_rate_init=0.001, \n",
    "                        power_t=0.5, \n",
    "                        max_iter=500, \n",
    "                        shuffle=True, \n",
    "                        random_state=2017, \n",
    "                        tol=0.0001, \n",
    "                        verbose=False, \n",
    "                        warm_start=True, \n",
    "                        momentum=0.9, \n",
    "                        nesterovs_momentum=True, \n",
    "                        early_stopping=False, \n",
    "                        validation_fraction=0.01, \n",
    "                        beta_1=0.9, \n",
    "                        beta_2=0.999, \n",
    "                        epsilon=1e-08).fit(train_x, train_y)\n",
    "\n",
    "#pickle.dump(nn_model,open('Neural_Network_model.sav', 'wb'))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test dataset = 0.5220361982\n",
      "--- time use: 0.0 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict_nn = nn_model.predict(test_x)\n",
    "print (\"RMSE on test dataset = %.10f\" % (rmse(predict_nn, test_y)))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Extra Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- time use: 2.15 minutes ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "start_time = time.time()\n",
    "extra_model = ExtraTreesRegressor(bootstrap=False, \n",
    "                                  max_depth=12, \n",
    "                                  min_samples_leaf=2,\n",
    "                                  min_samples_split=6,\n",
    "                                  n_estimators=250,\n",
    "                                  n_jobs=-1,\n",
    "                                  criterion='mse',\n",
    "                                  min_weight_fraction_leaf=0.0,\n",
    "                                  max_features='auto',\n",
    "                                  warm_start=False,\n",
    "                                  random_state=2017).fit(train_x, train_y)\n",
    "#pickle.dump(extra_model,open('extra_tree_model.sav', 'wb'))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test dataset = 0.4519042528\n",
      "--- time use: 0.0 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "predict_xt = extra_model.predict(test_x)\n",
    "print (\"RMSE on test dataset = %.10f\" % (rmse(predict_xt, test_y)))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- time use: 46.82 minutes ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "start_time = time.time()\n",
    "gb_model = GradientBoostingRegressor(loss='ls', \n",
    "                                 learning_rate=0.05, \n",
    "                                 n_estimators=300, \n",
    "                                 subsample=1.0, \n",
    "                                 criterion='friedman_mse', \n",
    "                                 min_samples_split=2, \n",
    "                                 min_samples_leaf=15, \n",
    "                                 min_weight_fraction_leaf=0.0, \n",
    "                                 max_depth=6, \n",
    "                                 min_impurity_split=1e-07, \n",
    "                                 init=None, \n",
    "                                 random_state=2017, \n",
    "                                 max_features=None, \n",
    "                                 alpha=0.9, \n",
    "                                 verbose=0, \n",
    "                                 max_leaf_nodes=None, \n",
    "                                 warm_start=False, \n",
    "                                 presort='auto').fit(train_x, train_y)\n",
    "#pickle.dump(gb_model,open('GBRegressor_model.sav', 'wb'))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test dataset = 0.4434266726\n",
      "--- time use: 0.01 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict_gb = gb_model.predict(test_x)\n",
    "print (\"RMSE on test dataset = %.10f\" % (rmse(predict_gb, test_y)))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### XGBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- time use: 0.97 minutes ---\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "start_time = time.time()\n",
    "#xgbclassifier\n",
    "xgb_model1 = xgb.XGBRegressor(max_depth=9, \n",
    "                             learning_rate=0.075, \n",
    "                             n_estimators=100, \n",
    "                             silent=True, \n",
    "                             objective='reg:linear', \n",
    "                             nthread=-1, \n",
    "                             gamma=0, \n",
    "                             min_child_weight=10,\n",
    "                             max_delta_step=0, \n",
    "                             subsample=1, \n",
    "                             colsample_bytree=1, \n",
    "                             colsample_bylevel=1, \n",
    "                             reg_alpha=0, \n",
    "                             reg_lambda=1, \n",
    "                             scale_pos_weight=1, \n",
    "                             base_score=0.5, \n",
    "                             seed=2017, \n",
    "                             missing=None).fit(train_x, train_y)\n",
    "#pickle.dump(xgb_model,open('XGBRegressor_model.sav', 'wb'))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test dataset = 0.4424128379\n",
      "--- time use: 0.0 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# predict\n",
    "predict_xgb1 = xgb_model1.predict(test_x)\n",
    "print (\"RMSE on test dataset = %.10f\" % (rmse(predict_xgb1, test_y)))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.77198\ttrain-rmse:1.77198\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 20 rounds.\n",
      "[50]\ttrain-rmse:0.376216\ttrain-rmse:0.376216\n",
      "[100]\ttrain-rmse:0.344028\ttrain-rmse:0.344028\n",
      "[150]\ttrain-rmse:0.329465\ttrain-rmse:0.329465\n",
      "[200]\ttrain-rmse:0.32233\ttrain-rmse:0.32233\n",
      "[250]\ttrain-rmse:0.31819\ttrain-rmse:0.31819\n",
      "[300]\ttrain-rmse:0.315029\ttrain-rmse:0.315029\n",
      "[350]\ttrain-rmse:0.313034\ttrain-rmse:0.313034\n",
      "[400]\ttrain-rmse:0.310896\ttrain-rmse:0.310896\n",
      "[450]\ttrain-rmse:0.309349\ttrain-rmse:0.309349\n",
      "--- time use: 4.62 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "#dval = xgb.DMatrix(X_val_FM, label=target_val)\n",
    "dtest = xgb.DMatrix(test_x, test_y)\n",
    "\n",
    "evallist  = [(dtrain,'train'), (dtrain,'train')]\n",
    "bst_param = {'max_depth':10,\n",
    "         'eta':0.1,\n",
    "         'min_child_weight':1,\n",
    "         'max_delta_step':0,\n",
    "         'gamma':1,\n",
    "         'lambda':1,\n",
    "         'alpha':3,\n",
    "         'colsample_bytree':0.3,\n",
    "         'subsample':1,\n",
    "         'eval_metric':'rmse',\n",
    "         'maximize':False,\n",
    "         'nthread':4}\n",
    "nrounds = 500\n",
    "xgb_fit = xgb.train(bst_param, \n",
    "                    dtrain, \n",
    "                    nrounds, \n",
    "                    evals = evallist, \n",
    "                    early_stopping_rounds = 20, \n",
    "                    verbose_eval = 50)\n",
    "\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test dataset = 0.4387737557\n",
      "--- time use: 0.0 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict_bst= xgb_fit.predict(dtest)\n",
    "print (\"RMSE on test dataset = %.10f\" % (rmse(predict_bst, test_y)))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Adaboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- time use: 4.24 minutes ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "start_time = time.time()\n",
    "\n",
    "ada_model = AdaBoostRegressor(base_estimator=None, \n",
    "                               n_estimators=90, \n",
    "                               learning_rate=0.5, \n",
    "                               random_state=2017).fit(train_x,train_y)\n",
    "#pickle.dump(ada_model,open('AdaBoost_model.sav', 'wb'))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test dataset = 0.4826711222\n",
      "--- time use: 0.0 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# pridiction\n",
    "predict_ada = ada_model.predict(test_x)\n",
    "print (\"RMSE on test dataset = %.10f\" % (rmse(predict_ada, test_y)))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- time use: 4.01 minutes ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "start_time = time.time()\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=200,\n",
    "                                  max_features = 0.55,\n",
    "                                  min_samples_leaf = 12,\n",
    "                                  oob_score = True,\n",
    "                                  max_depth = 15,\n",
    "                                  n_jobs = -1,\n",
    "                                  random_state = 2017).fit(train_x, train_y)\n",
    "#pickle.dump(rf_model,open('random_forest_model.sav', 'wb'))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test dataset = 0.4481836366\n",
      "--- time use: 0.0 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# predict\n",
    "predict_rf = rf_model.predict(test_x)\n",
    "print (\"RMSE on test dataset = %.10f\" % (rmse(predict_rf, test_y)))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Linear Regression (Baselineï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- time use: 0.05 minutes ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "start_time = time.time()\n",
    "lr_model = LinearRegression(n_jobs = -1).fit(train_x, train_y)\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test dataset = 0.46\n",
      "--- time use: 0.0 minutes ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "predict_linear = lr_model.predict(test_x)\n",
    "print (\"RMSE on test dataset = %.2f\" % (rmse(predict_linear, test_y)))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- time use: 1.13 minutes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "start_time = time.time()\n",
    "\n",
    "bag = BaggingRegressor(xgb_model1, \n",
    "                       n_estimators=1, \n",
    "                       random_state=2017,\n",
    "                       n_jobs=-1,\n",
    "                       verbose=True).fit(train_x,train_y)\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test dataset = 0.4521598698\n",
      "--- time use: 0.0 minutes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# predict\n",
    "predict_bag = bag.predict(test_x)\n",
    "print (\"RMSE on test dataset = %.10f\" % (rmse(predict_bag, test_y)))\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_stack = np.stack((0.1*np.log1p(predict_bag), \n",
    "                                      0.2*np.log1p(predict_rf), \n",
    "                                      0.3*np.log1p(predict_xgb1),\n",
    "                                      0.4*np.log1p(predict_bst)\n",
    "                                      #np.log1p(predict_gb)\n",
    "                                      ), axis = 1)\n",
    "d_stack = xgb.DMatrix(x_train_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14814, 4)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# linear_stack = LinearRegression(n_jobs = -1).fit(x_train_stack, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "evallist  = [(x_train_stack,'train'), (x_train_stack,'train')]\n",
    "stack_param = {'max_depth':10,\n",
    "         'eta':0.1,\n",
    "         'min_child_weight':1,\n",
    "         'max_delta_step':0,\n",
    "         'gamma':1,\n",
    "         'lambda':1,\n",
    "         'alpha':3,\n",
    "         'colsample_bytree':0.3,\n",
    "         'subsample':1,\n",
    "         'eval_metric':'rmse',\n",
    "         'maximize':False,\n",
    "         'nthread':4}\n",
    "nrounds = 500\n",
    "stack_model = xgb.train(stack_param, \n",
    "                          dtrain, \n",
    "                          nrounds, \n",
    "                          evals = evallist, \n",
    "                          early_stopping_rounds = 20, \n",
    "                          verbose_eval = 50)\n",
    "print(\"--- time use: %s minutes ---\" % round(((time.time() - start_time)/60),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
